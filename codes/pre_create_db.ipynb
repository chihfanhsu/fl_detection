{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pts_loader import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_res = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_types = ['trainset', 'testset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset\n",
      "loading... afw\n",
      "loading... helen\n",
      "loading... lfpw\n",
      "testset\n",
      "loading... 300w\n",
      "loading... helen\n",
      "loading... ibug\n",
      "loading... lfpw\n",
      "loading... cofw\n"
     ]
    }
   ],
   "source": [
    "db_all = {}\n",
    "for types in set_types:\n",
    "    print(types)\n",
    "    db_path = 'G:/datasets/facial_landmarks/'+types+'/'\n",
    "    if types == 'trainset':\n",
    "        db_name = ['afw','helen','lfpw']\n",
    "        img_sub = ['.jpg','.jpg','.png']\n",
    "    elif types == 'testset':\n",
    "        db_name = ['300w','helen','ibug','lfpw','cofw']\n",
    "        img_sub = ['.png','.jpg','.jpg','.png','.jpg']\n",
    "    fd_imgs=[]\n",
    "    fd_pts=[]\n",
    "    fd_dataset = []\n",
    "    fd_fn = []\n",
    "    for dn, sub in zip(db_name, img_sub):\n",
    "        print('loading...', dn)\n",
    "        os.listdir(db_path+dn+'/');#print(os.listdir(db_path+dn+'/'))\n",
    "\n",
    "        db_folder = db_path+dn+'/'\n",
    "        fns = [f.split('.')[0] for f in os.listdir(db_folder) if os.path.isfile(os.path.join(db_folder, f))];#print(list(set(fns)))\n",
    "        fns = list(set(fns))\n",
    "        fns.sort()\n",
    "\n",
    "        # f = '2437602091_1'\n",
    "        for f in fns:\n",
    "    #         print(f)\n",
    "            #f = fns[1];\n",
    "            image_path = db_folder + f\n",
    "            #load image and pts\n",
    "            img = cv2.imread(image_path + sub, 1)\n",
    "            pts = np.ndarray.astype(np.round(np.asarray(load(image_path + '.pts'))), dtype = 'int32')\n",
    "            # get face location\n",
    "            fl_x_min = np.min(pts[:,0])\n",
    "            fl_x_max = np.max(pts[:,0])\n",
    "            fl_y_min = np.min(pts[:,1])\n",
    "            fl_y_max = np.max(pts[:,1])\n",
    "            # 'landmark out of boundary' pads with zeros\n",
    "    #         if (fl_x_min < 0) or (fl_y_min < 0) or (fl_y_max > (img.shape[0]-1)) or (fl_x_max > (img.shape[1]-1)):\n",
    "\n",
    "    #             print ('landmark out of boundary')\n",
    "            # clac bounding box\n",
    "            bx_size = int(1.3*max((fl_y_max - fl_y_min), (fl_x_max - fl_x_min)))\n",
    "            bx_center = ((fl_x_max + fl_x_min)/2,(fl_y_max + fl_y_min)/2); #print(bx_center)\n",
    "            bx_lt =  np.ndarray.astype(np.round(bx_center - np.asarray(bx_size/2)), dtype = 'int32'); #print(\"bx_lt\",bx_lt)\n",
    "            bx_rb =  bx_lt+bx_size; #print(\"bx_rb\",bx_rb)\n",
    "            # create space \n",
    "            crop_image = np.zeros((bx_size,bx_size,3),dtype=np.uint8)\n",
    "\n",
    "            img_t = 0\n",
    "            img_l = 0\n",
    "            img_b = bx_size\n",
    "            img_r = bx_size\n",
    "\n",
    "            if bx_lt[0] < 0:\n",
    "                img_l = abs(bx_lt[0])\n",
    "                pts = pts + [abs(bx_lt[0]),0]\n",
    "                bx_lt[0] = 0\n",
    "\n",
    "            if bx_lt[1] < 0:\n",
    "                img_t = abs(bx_lt[1])\n",
    "                pts = pts + [0,abs(bx_lt[1])]\n",
    "                bx_lt[1] = 0\n",
    "\n",
    "            if bx_rb[0] >= img.shape[1]:\n",
    "                img_r = bx_size - (bx_rb[0] - img.shape[1])\n",
    "                bx_rb[0] = img.shape[1]\n",
    "\n",
    "            if bx_rb[1] >= img.shape[0]:\n",
    "                img_b = bx_size - (bx_rb[1] - img.shape[0])\n",
    "                bx_rb[1] = img.shape[0]\n",
    "\n",
    "    #         print(img_l,img_t)\n",
    "    #         print(img_r,img_b)\n",
    "    #         print(\"bx_lt\",bx_lt)\n",
    "    #         print(\"bx_rb\",bx_rb)\n",
    "            # crop image\n",
    "            crop_image[img_t:img_b,img_l:img_r]  = crop_image[img_t:img_b,img_l:img_r] + img[bx_lt[1]:(bx_rb[1]),\n",
    "                                                                                             bx_lt[0]:(bx_rb[0]),:]\n",
    "            shift_pts = pts - bx_lt\n",
    "            resize_ratio = tar_res/crop_image.shape[1]\n",
    "\n",
    "            # resized dataset\n",
    "            res_img = cv2.resize(crop_image, dsize=(tar_res, tar_res), interpolation=cv2.INTER_CUBIC)\n",
    "            resized_pts = np.ndarray.astype(np.round(shift_pts*resize_ratio), dtype = 'int32')\n",
    "\n",
    "            fd_imgs.append(np.asarray(res_img))\n",
    "            fd_pts.append(np.asarray(resized_pts))\n",
    "            fd_dataset.append(dn)\n",
    "            fd_fn.append(dn + '_'+ f +'.png')\n",
    "\n",
    "\n",
    "            #plot and check\n",
    "            # plt.imshow(res_img)\n",
    "            # plt.show()\n",
    "\n",
    "            fig_img = res_img.copy()\n",
    "    #         for i in range(resized_pts.shape[0]):\n",
    "    #             #print(pts.iloc[i,0],pts.iloc[i,1])\n",
    "    #             cv2.circle(fig_img,(resized_pts[i,0],\n",
    "#                                     resized_pts[i,1]), 2, (255,0,0), -1)\n",
    "#             plt.imshow(fig_img)\n",
    "#             plt.imsave(db_path+'crop_img/' + dn + '_'+ f +'.png', fig_img, format=\"png\")\n",
    "#             plt.close().png\n",
    "        #     plt.show()\n",
    "            cv2.imwrite(db_path+'crop_img/' + dn + '_'+ f +'.png', res_img) \n",
    "    db = {}\n",
    "    db['img'] = np.asarray(fd_imgs)\n",
    "    db['pts'] = np.asarray(fd_pts)\n",
    "    db['dataset'] = np.asarray(fd_dataset)\n",
    "    db['file_name'] = np.asarray(fd_fn)\n",
    "    db_all[types] = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['testset', 'trainset'])\n",
      "dict_keys(['img', 'file_name', 'dataset', 'pts'])\n",
      "dict_keys(['img', 'file_name', 'dataset', 'pts'])\n",
      "(3148, 68, 2)\n",
      "(3148, 224, 224, 3)\n",
      "(1796, 68, 2)\n",
      "(1796, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(db_all.keys())\n",
    "print(db_all['trainset'].keys())\n",
    "print(db_all['testset'].keys())\n",
    "print(db_all['trainset']['pts'].shape)\n",
    "print(db_all['trainset']['img'].shape)\n",
    "print(db_all['testset']['pts'].shape)\n",
    "print(db_all['testset']['img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('G:/datasets/facial_landmarks/combined_new.pickle', 'wb') as handle:\n",
    "    pickle.dump(db_all, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image and points to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for dn in db_name:\n",
    "#     os.listdir(db_path+dn+'/');print(os.listdir(db_path+dn+'/'))\n",
    "#     db = {}\n",
    "#     db_imgs={}\n",
    "#     db_pts={}\n",
    "#     for t in os.listdir(db_path+dn+'/'):\n",
    "#         db_folder = db_path+dn+'/'+t+'/'\n",
    "#         fns = [f.split('.')[0] for f in os.listdir(db_folder) if os.path.isfile(os.path.join(db_folder, f))];#print(list(set(fns)))\n",
    "#         fns = list(set(fns))\n",
    "#         fns.sort()\n",
    "\n",
    "#         fd_imgs=[]\n",
    "#         fd_pts=[]\n",
    "#         for f in fns:\n",
    "#             image_path = db_folder + f\n",
    "#             img = cv2.imread(image_path +'.png', 1)\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#             ratio = img.shape[0]/tar_res\n",
    "#             img = cv2.resize(img,(int(img.shape[0]/ratio),int(img.shape[1]/ratio)),interpolation=cv2.INTER_CUBIC)\n",
    "#             fd_imgs.append(np.asarray(img))\n",
    "#             pts = pandas.read_csv(image_path +'.txt', header=None);# print(pts)\n",
    "#             fd_pts.append(np.around(pts.values/ratio).astype(np.int32))\n",
    "            \n",
    "#         # print\n",
    "# #         fig_img = fd_imgs[0].copy()\n",
    "# #         for i in range(fd_pts[0].shape[0]):\n",
    "# #             #print(pts.iloc[i,0],pts.iloc[i,1])\n",
    "# #             cv2.circle(fig_img,(fd_pts[0][i,0],fd_pts[0][i,1]), 2, (255,0,0), -1)\n",
    "# #         plt.imshow(fig_img)\n",
    "# #         plt.show()\n",
    "\n",
    "#         db_imgs[t]= np.asarray(fd_imgs)\n",
    "#         db_pts[t] = np.asarray(fd_pts)\n",
    "\n",
    "#     # check shape\n",
    "#     print(db_imgs.keys(),db_pts.keys())\n",
    "#     for k in list(db_imgs.keys()):\n",
    "#         print(db_imgs[k].shape, db_pts[k].shape)\n",
    "#     # save to db\n",
    "#     db['img']= db_imgs\n",
    "#     db['pts']= db_pts\n",
    "    \n",
    "#     with open('./dataset/'+dn+'.pickle', 'wb') as handle:\n",
    "#         pickle.dump(db, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
