{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code examples from shekkizh [https://github.com/shekkizh/FCN.tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mmnet\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "import os, sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import TensorflowUtils as utils\n",
    "import vgg19 as vgg\n",
    "import pickle\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import random\n",
    "import cv2\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''setting'''\n",
    "gpus = [0] # Here I set CUDA to only see one GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(i) for i in gpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_dir = './fcn/'\n",
    "MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'\n",
    "data_dir = './dataset/'\n",
    "logs_dir = model_dir+'logs/'\n",
    "debug = False\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSESS = int(68 + 1)\n",
    "IMAGE_SIZE = 224\n",
    "learning_rate = 1e-4\n",
    "batch_size = 4\n",
    "MAX_ITERATION = int(1e5 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(x, train_phase, name='bn_layer'):\n",
    "    #with tf.variable_scope(name) as scope:\n",
    "    batch_norm = tf.layers.batch_normalization(\n",
    "            inputs=x,\n",
    "            momentum=0.9, epsilon=1e-5,\n",
    "            center=True, scale=True,\n",
    "            training = train_phase,\n",
    "            name=name\n",
    "    )\n",
    "    return batch_norm\n",
    "\n",
    "def conv_blk (inputs,n_filter, train_phase, name = 'conv_blk'):\n",
    "    with tf.variable_scope(name):\n",
    "        c1 = tf.layers.conv2d(inputs, filters=n_filter[0], kernel_size=[3,3], strides=(1,1), padding='same')       \n",
    "        c1_bn = batch_norm(c1, train_phase, name='c1_bn')\n",
    "        c1_relu = tf.nn.relu(c1_bn)\n",
    "        c2 = tf.layers.conv2d(c1_relu,filters=n_filter[1],kernel_size=[3,3],strides=(1,1),padding='same')        \n",
    "        c2_bn = batch_norm(c2, train_phase, name='c2_bn')\n",
    "        c2_relu = tf.nn.relu(c2_bn)\n",
    "        return c2_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image, train_phase, keep_prob):\n",
    "    # model\n",
    "    with tf.variable_scope(\"inference\"):\n",
    "        # trnasfer VGG-19\n",
    "        # convolutional part\n",
    "#         r1 = tf.layers.max_pooling2d(image,pool_size=[2,2],strides=(2,2))\n",
    "\n",
    "        h1 = conv_blk(image, [64,64], train_phase, name='conv_blk1')\n",
    "        m1 = tf.layers.max_pooling2d(h1,pool_size=[2,2],strides=(2,2))\n",
    "        print('[h1] ',h1)\n",
    "        h2 = conv_blk(m1, [128,128], train_phase, name='conv_blk2')\n",
    "        m2 = tf.layers.max_pooling2d(h2,pool_size=[2,2],strides=(2,2))\n",
    "        print('[h2] ',h2)\n",
    "        h3 = conv_blk(m2, [256,256], train_phase, name='conv_blk3')\n",
    "        m3 = tf.layers.max_pooling2d(h3,pool_size=[2,2],strides=(2,2))\n",
    "        print('[h3] ',h3)\n",
    "        h4 = conv_blk(m3, [512,512], train_phase, name='conv_blk4')\n",
    "        m4 = tf.layers.max_pooling2d(h4,pool_size=[2,2],strides=(2,2))\n",
    "        print('[h4] ',h4)\n",
    "        # conv layers\n",
    "        h5 = conv_blk(m4, [1024,1024], train_phase, name='conv_blk5')\n",
    "        m5 = tf.layers.max_pooling2d(h5,pool_size=[2,2],strides=(2,2))\n",
    "        print('[h5] ',h5)\n",
    "        h6=tf.contrib.layers.conv2d(m5, NUM_OF_CLASSESS, [1,1], stride=1,padding='SAME')\n",
    "        print('[h6] ',h6)\n",
    "        # now to upscale to actual image size\n",
    "        deconv_shape1 = h5.get_shape()\n",
    "        conv_t1 = tf.contrib.layers.conv2d_transpose(h6, deconv_shape1[3].value, [4, 4],\n",
    "                                                     stride=2, padding='SAME',activation_fn=None)\n",
    "        print('[conv_t1] ',conv_t1)\n",
    "        fuse_1 = tf.add(conv_t1, h5, name=\"fuse_1\");#print(\"fuse_1\",fuse_1)\n",
    "\n",
    "        deconv_shape2 = h4.get_shape()\n",
    "        conv_t2 = tf.contrib.layers.conv2d_transpose(fuse_1, deconv_shape2[3].value, [4, 4],\n",
    "                                                     stride=2, padding='SAME',activation_fn=None)\n",
    "        print('[conv_t2] ',conv_t2)\n",
    "        fuse_2 = tf.add(conv_t2, h4, name=\"fuse_2\");#print(\"fuse_2\",fuse_2)\n",
    "\n",
    "        conv_t3 = tf.contrib.layers.conv2d_transpose(fuse_2, NUM_OF_CLASSESS, [16, 16],\n",
    "                                                     stride=8, padding='SAME',activation_fn=None);#print(\"conv_t3\",conv_t3)\n",
    "        print('[conv_t3] ',conv_t3)\n",
    "        annotation_pred = tf.argmax(conv_t3, axis=3, name=\"prediction\");print(\"annotation_pred\",annotation_pred)\n",
    "        return tf.expand_dims(annotation_pred, dim=3), conv_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[h1]  Tensor(\"inference/conv_blk1/Relu_1:0\", shape=(?, 224, 224, 64), dtype=float32)\n",
      "[h2]  Tensor(\"inference/conv_blk2/Relu_1:0\", shape=(?, 112, 112, 128), dtype=float32)\n",
      "[h3]  Tensor(\"inference/conv_blk3/Relu_1:0\", shape=(?, 56, 56, 256), dtype=float32)\n",
      "[h4]  Tensor(\"inference/conv_blk4/Relu_1:0\", shape=(?, 28, 28, 512), dtype=float32)\n",
      "[h5]  Tensor(\"inference/conv_blk5/Relu_1:0\", shape=(?, 14, 14, 1024), dtype=float32)\n",
      "[h6]  Tensor(\"inference/Conv/Relu:0\", shape=(?, 7, 7, 69), dtype=float32)\n",
      "[conv_t1]  Tensor(\"inference/Conv2d_transpose/BiasAdd:0\", shape=(?, 14, 14, 1024), dtype=float32)\n",
      "[conv_t2]  Tensor(\"inference/Conv2d_transpose_1/BiasAdd:0\", shape=(?, 28, 28, 512), dtype=float32)\n",
      "[conv_t3]  Tensor(\"inference/Conv2d_transpose_2/BiasAdd:0\", shape=(?, 224, 224, 69), dtype=float32)\n",
      "annotation_pred Tensor(\"inference/prediction:0\", shape=(?, 224, 224), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# setting inputs\n",
    "keep_probability = tf.placeholder(tf.float32, name=\"keep_probabilty\")\n",
    "image = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 3], name=\"input_image\")\n",
    "annotation = tf.placeholder(tf.int32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name=\"annotation\")\n",
    "train_phase = tf.placeholder(tf.bool, name='phase_train')\n",
    "\n",
    "pred_annotation, logits = inference(image, train_phase, keep_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_parameters 37486538\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "#         print(shape)\n",
    "#         print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "#             print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "#         print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print('total_parameters', total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                      labels=tf.squeeze(annotation, squeeze_dims=[3]),\n",
    "                                                                      name=\"entropy\")))\n",
    "loss_summary = tf.summary.scalar(\"entropy\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss_val, var_list):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    grads = optimizer.compute_gradients(loss_val, var_list=var_list)\n",
    "    if debug:\n",
    "        # print(len(var_list))\n",
    "        for grad, var in grads:\n",
    "            utils.add_gradient_summary(grad, var)\n",
    "    return optimizer.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up summary op...\n",
      "Setting up Saver...\n"
     ]
    }
   ],
   "source": [
    "trainable_var = tf.trainable_variables()\n",
    "if debug:\n",
    "    for var in trainable_var:\n",
    "        utils.add_to_regularization_and_summary(var)\n",
    "        \n",
    "train_op = train(loss, trainable_var)\n",
    "# initialize the model\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "print(\"Setting up summary op...\")\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "print(\"Setting up Saver...\")\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./fcn/logs/model.ckpt-60000\n",
      "Loading sucessfully\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "if (training == False):\n",
    "    ckpt = tf.train.get_checkpoint_state(logs_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('Loading sucessfully')\n",
    "    else:\n",
    "        print('No checkpoint file found')\n",
    "        raise\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "# create two summary writers to show training loss and validation loss in the same graph\n",
    "# need to create two folders 'train' and 'validation' inside FLAGS.logs_dir\n",
    "train_writer = tf.summary.FileWriter(logs_dir+'/train', sess.graph)\n",
    "validation_writer = tf.summary.FileWriter(logs_dir+'/validation', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data iterator\n",
    "def get_batch(X, Y, batch_size = 32):\n",
    "    # print ('shuffle training dataset')\n",
    "    idx = np.arange(len(X))    \n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        tb = int(len(X)/batch_size)\n",
    "        #print('total batches %d' % tb)\n",
    "        for b_idx in range(tb):\n",
    "            tar_idx = idx[(b_idx*batch_size):((b_idx+1)*batch_size)]\n",
    "            t_batch_x = X[tar_idx]\n",
    "            t_batch_y = Y[tar_idx]\n",
    "            # print(b_idx, t_batch_x.shape, t_batch_y.shape)\n",
    "            yield t_batch_x, t_batch_y\n",
    "            \n",
    "def data_augmentation(images, pts, rot=(-30, 30), s=(0.6, 1.0)):\n",
    "    keypoints_on_images = []\n",
    "    for idx_img in range(images.shape[0]):\n",
    "        image = images[idx_img]\n",
    "        height, width = image.shape[0:2]\n",
    "        keypoints = []\n",
    "        for p in range(pts.shape[1]):\n",
    "            keypoints.append(ia.Keypoint(x=pts[idx_img,p,0], y=pts[idx_img,p,1]))\n",
    "        keypoints_on_images.append(ia.KeypointsOnImage(keypoints, shape=image.shape))\n",
    "\n",
    "    seq = iaa.Sequential([iaa.Affine(rotate=rot,scale=s)])\n",
    "    seq_det = seq.to_deterministic() # call this for each batch again, NOT only once at the start\n",
    "\n",
    "    # augment keypoints and images\n",
    "    images_aug = seq_det.augment_images(images)\n",
    "    keypoints_aug = seq_det.augment_keypoints(keypoints_on_images)\n",
    "    \n",
    "    pts_aug=[]\n",
    "    for img_idx, keypoints_after in enumerate(keypoints_aug):\n",
    "        img_pts_aug=[]\n",
    "        for kp_idx, keypoint in enumerate(keypoints_after.keypoints):\n",
    "            img_pts_aug.append([round(keypoint.x), round(keypoint.y)])\n",
    "        pts_aug.append(np.asarray(img_pts_aug))\n",
    "\n",
    "    pts_aug = np.asarray(pts_aug).astype(np.int32)\n",
    "    \n",
    "#     print('images_aug', images_aug.shape)\n",
    "#     print('pts_aug', pts_aug.shape)\n",
    "    return images_aug, pts_aug\n",
    "\n",
    "# write image to \n",
    "def write_result(batch_xs_valid, pts_maps, iter_num):\n",
    "    b = random.randint(0, batch_xs_valid.shape[0]-1)\n",
    "    img = batch_xs_valid[b].copy()\n",
    "    pts = map2pts(pts_maps)[b] #print(pts)\n",
    "#     print(img.shape)\n",
    "#     print(pts.shape)\n",
    "    for p in range(pts.shape[0]):\n",
    "        #print(\"p\",p, pts[p+1,0],pts[p+1,1])\n",
    "        cv2.circle(img,(pts[p,0],pts[p,1]), 2, (255,0,0), -1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cv2.imwrite(model_dir+'imgs/infer_'+str(iter_num)+'.png', img) \n",
    "\n",
    "def eval_norm_error_image(infer, gt):\n",
    "    # loss of all landmarks\n",
    "    l2d = np.sum(np.sqrt(np.sum(np.square(infer-gt),axis=2)), axis=1)\n",
    "    # distance of eye corners\n",
    "    cd = np.sqrt(np.sum(np.square(gt[:,45,:]-gt[:,36,:]),axis=1))\n",
    "    norm_error_image = l2d/cd/68\n",
    "    return norm_error_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pts2map(ys):\n",
    "    #print(ys.shape)\n",
    "    maps = np.zeros(shape=(ys.shape[0],IMAGE_SIZE,IMAGE_SIZE,1));#print(maps.shape)\n",
    "    for i in range(ys.shape[0]):\n",
    "        for p in range(ys.shape[1]):\n",
    "            if(((ys[i,p,0]) < IMAGE_SIZE) & ((ys[i,p,1]) < IMAGE_SIZE) & (ys[i,p,0] > -1) & (ys[i,p,1] > -1)):\n",
    "                maps[i,ys[i,p,1],  ys[i,p,0],0] = p+1 # shift label from 0:68 to 1:69\n",
    "    return maps\n",
    "\n",
    "def map2pts(pts_maps):\n",
    "    b_idxs = []\n",
    "    for b in range(pts_maps.shape[0]): \n",
    "        idxs = []\n",
    "        for p in range(pts_maps.shape[3]): \n",
    "            idx = np.unravel_index(np.argmax(pts_maps[b,...,p], axis=None), pts_maps[b,...,p].shape)\n",
    "            idxs.append(idx)\n",
    "        b_idxs.append(np.asarray(idxs))\n",
    "    b_idxs = np.asarray(b_idxs);#print(b_idxs.shape)\n",
    "    b_idxs = b_idxs[:,1:,:]\n",
    "    # change index\n",
    "    ret = np.concatenate((b_idxs[...,1][...,np.newaxis],b_idxs[...,0][...,np.newaxis]),axis=2)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img', 'pts'])\n",
      "dict_keys(['trainset', 'testset'])\n",
      "(2000, 68, 2)\n",
      "(2000, 224, 224, 3)\n",
      "(330, 68, 2)\n",
      "(330, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "db_helen = pickle.load(open(data_dir+\"HELEN.pickle\", \"rb\" ) )\n",
    "# print the data structure\n",
    "print(db_helen.keys())\n",
    "print(db_helen['pts'].keys())\n",
    "# print the shape of tratining set\n",
    "print(db_helen['pts']['trainset'].shape)\n",
    "print(db_helen['img']['trainset'].shape)\n",
    "# print the shape of testing set\n",
    "print(db_helen['pts']['testset'].shape)\n",
    "print(db_helen['img']['testset'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declear data iterator\n",
    "train_batches = get_batch(db_helen['img']['trainset'], db_helen['pts']['trainset'], batch_size = batch_size)\n",
    "valid_batches = get_batch(db_helen['img']['testset'], db_helen['pts']['testset'], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if training ==True:\n",
    "    max_validloss = 99999\n",
    "    for itr in range(MAX_ITERATION):\n",
    "        # prepare training input\n",
    "        batch_xs, batch_ys = next(train_batches)\n",
    "        batch_xs_aug, batch_ys_aug = data_augmentation(batch_xs, batch_ys)\n",
    "        batch_ymap_aug = pts2map(batch_ys_aug)\n",
    "\n",
    "        feed_dict = {image: batch_xs_aug, annotation: batch_ymap_aug, keep_probability: 0.85, train_phase:True}\n",
    "        sess.run([extra_update_ops,train_op], feed_dict=feed_dict)\n",
    "\n",
    "        if itr % 500 == 0:\n",
    "            feed_dict = {image: batch_xs_aug, annotation: batch_ymap_aug, keep_probability: 0.85, train_phase:False}\n",
    "            train_loss, summary_str = sess.run([loss, loss_summary], feed_dict=feed_dict)\n",
    "            print(\"[T] Step: %d, loss:%g\" % (itr, train_loss))\n",
    "            train_writer.add_summary(summary_str, itr)\n",
    "        # validation\n",
    "        if itr % 1000 == 0:\n",
    "            # prepare inputs\n",
    "            batch_xs_valid, batch_ys_valid = next(valid_batches)\n",
    "            batch_ymap_valid = pts2map(batch_ys_valid);# print(batch_ymap_valid.shape)\n",
    "\n",
    "            feed_dict = {image: batch_xs_valid, annotation: batch_ymap_valid, keep_probability: 1.0, train_phase:False}\n",
    "            valid_loss, pts_maps, summary_sva=sess.run([loss, tf.nn.softmax(logits), loss_summary], feed_dict=feed_dict)\n",
    "            # write result figure to the imgs/\n",
    "            write_result(batch_xs_valid, pts_maps, itr)\n",
    "            # save validation log\n",
    "            validation_writer.add_summary(summary_sva, itr)\n",
    "            # save the ckpt if reachings better loss\n",
    "            if valid_loss < max_validloss:\n",
    "                saver.save(sess, logs_dir + \"model.ckpt\", itr)\n",
    "                print(\"[V*] Step: %d, loss:%g\" % (itr, valid_loss))\n",
    "                max_validloss = valid_loss\n",
    "            else:\n",
    "                print(\"[V] Step: %d, loss:%g\" % (itr, valid_loss))\n",
    "else:\n",
    "    testing_batch = 30\n",
    "    pt = []\n",
    "    for t in range(int(db_helen['img']['testset'].shape[0]/testing_batch)):\n",
    "        t_batch_x = db_helen['img']['testset'][(t*testing_batch):((t+1)*testing_batch)]\n",
    "        t_batch_y = db_helen['pts']['testset'][(t*testing_batch):((t+1)*testing_batch)]\n",
    "        feed_dict = {image: t_batch_x, keep_probability: 1.0, train_phase:False}\n",
    "        \n",
    "        pts_maps=sess.run(tf.nn.softmax(logits), feed_dict=feed_dict)\n",
    "        infered_pts = map2pts(pts_maps)\n",
    "        pt.append(infered_pts)\n",
    "    \n",
    "    infered_pts = np.reshape(np.asarray(pt),newshape=[-1,68,2])\n",
    " \n",
    "    for idx, content in enumerate(zip(db_helen['img']['testset'],infered_pts)):\n",
    "        img = content[0].copy()\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        for kp_idx, keypoint in enumerate(content[1]):\n",
    "            cv2.circle(img,(keypoint[0],keypoint[1]), 2, (0,255,0), -1)\n",
    "            cv2.putText(img, str(kp_idx), (keypoint[0],keypoint[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.3,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "        cv2.imwrite(model_dir + '/pred_result/'+ str(idx)+ '.png', img) \n",
    "    \n",
    "    norm_error_image = eval_norm_error_image(infered_pts, db_helen['pts']['testset'])\n",
    "    pandas.DataFrame({'loss':norm_error_image}).to_csv(model_dir + 'norm_error_image.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
