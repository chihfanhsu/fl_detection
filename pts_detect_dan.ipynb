{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mmnet\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# google 的 NN coding 套件\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''setting'''\n",
    "gpus = [0] # Here I set CUDA to only see one GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(i) for i in gpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=224\n",
    "batch_size = 16\n",
    "MAX_ITERATION = int(1e5 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset/'\n",
    "logs_dir = './dan/logs/'\n",
    "MAX_ITERATION = int(1e5 + 1)\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img', 'pts'])\n"
     ]
    }
   ],
   "source": [
    "db_helen = pickle.load(open( data_dir+\"HELEN.pickle\", \"rb\" ) )\n",
    "print(db_helen.keys())\n",
    "#db_300W['img'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(x, train_phase, name='bn_layer'):\n",
    "    #with tf.variable_scope(name) as scope:\n",
    "    batch_norm = tf.layers.batch_normalization(\n",
    "            inputs=x,\n",
    "            momentum=0.9, epsilon=1e-5,\n",
    "            center=True, scale=True,\n",
    "            training = train_phase,\n",
    "            name=name\n",
    "    )\n",
    "    return batch_norm\n",
    "\n",
    "def conv_blk (inputs,n_filter, train_phase, name = 'conv_blk'):\n",
    "    with tf.variable_scope(name):\n",
    "        c1 = tf.layers.conv2d(inputs, filters=n_filter[0], kernel_size=[3,3], strides=(1,1), padding='same')       \n",
    "        c1_bn = batch_norm(c1, train_phase, name='c1_bn')\n",
    "        c1_relu = tf.nn.relu(c1_bn)\n",
    "        c2 = tf.layers.conv2d(c1_relu,filters=n_filter[1],kernel_size=[3,3],strides=(1,1),padding='same')        \n",
    "        c2_bn = batch_norm(c2, train_phase, name='c2_bn')\n",
    "        c2_relu = tf.nn.relu(c2_bn)\n",
    "        return c2_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FF_NN(inputs, train_phase, keeprate):\n",
    "    h1 = conv_blk(inputs, [64,64], train_phase, name='conv_blk1')\n",
    "    m1 = tf.layers.max_pooling2d(h1,pool_size=[2,2],strides=(2,2))\n",
    "\n",
    "    h2 = conv_blk(m1, [128,128], train_phase, name='conv_blk2')\n",
    "    m2 = tf.layers.max_pooling2d(h2,pool_size=[2,2],strides=(2,2))\n",
    "\n",
    "    h3 = conv_blk(m2, [256,256], train_phase, name='conv_blk3')\n",
    "    m3 = tf.layers.max_pooling2d(h3,pool_size=[2,2],strides=(2,2))\n",
    "\n",
    "    h4 = conv_blk(m3, [512,512], train_phase, name='conv_blk4')\n",
    "    m4 = tf.layers.max_pooling2d(h4,pool_size=[2,2],strides=(2,2))\n",
    "\n",
    "    flt = tf.layers.flatten(m4)\n",
    "\n",
    "    # fully connected part\n",
    "    f1_do = tf.layers.dropout(flt,rate=keeprate)\n",
    "    f1 = tf.layers.dense(f1_do,256,activation=None)\n",
    "    f1_bn = batch_norm(f1, train_phase, name='f1_bn')\n",
    "    f1_relu = tf.nn.relu(f1_bn)\n",
    "    \n",
    "    f2 = tf.layers.dense(f1_relu,136,activation=None)\n",
    "    y_out = tf.reshape(f2, shape=[-1,68,2])\n",
    "    \n",
    "    return y_out, f1_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/zjjMaiMai/Deep-Alignment-Network-A-convolutional-neural-network-for-robust-face-alignment/blob/master/DAN_V2/dan_model.py\n",
    "# \"shape\" means points\n",
    "def __calc_affine_params(from_shape,to_shape):\n",
    "    from_shape = tf.cast(from_shape,dtype=tf.float32)    \n",
    "    to_shape = tf.cast(to_shape,dtype=tf.float32)\n",
    "    from_shape = tf.reshape(from_shape,[-1,68,2])\n",
    "    to_shape = tf.reshape(to_shape,[-1,68,2])\n",
    "\n",
    "    from_mean = tf.reduce_mean(from_shape, axis=1, keepdims=True)\n",
    "    to_mean = tf.reduce_mean(to_shape, axis=1, keepdims=True)\n",
    "\n",
    "    from_centralized = from_shape - from_mean\n",
    "    to_centralized = to_shape - to_mean\n",
    "\n",
    "    dot_result = tf.reduce_sum(tf.multiply(from_centralized, to_centralized), axis=[1, 2])\n",
    "    norm_pow_2 = tf.pow(tf.norm(from_centralized, axis=[1, 2]), 2)\n",
    "\n",
    "    a = dot_result / norm_pow_2\n",
    "    b = tf.reduce_sum(tf.multiply(from_centralized[:, :, 0], to_centralized[:, :, 1]) - tf.multiply(from_centralized[:, :, 1], to_centralized[:, :, 0]), 1) / norm_pow_2\n",
    "\n",
    "    r = tf.reshape(tf.stack([a, b, -b, a], axis=1), [-1, 2, 2])\n",
    "    t = to_mean - tf.matmul(from_mean, r)\n",
    "    return r,t\n",
    "\n",
    "def __affine_image(imgs,r,t):\n",
    "    # The Tensor [imgs].format is [NHWC]\n",
    "    r = tf.matrix_inverse(r)\n",
    "    r = tf.matrix_transpose(r)\n",
    "\n",
    "    rm = tf.reshape(tf.pad(r, [[0, 0], [0, 0], [0, 1]], mode='CONSTANT'), [-1, 6])\n",
    "    rm = tf.pad(rm, [[0, 0], [0, 2]], mode='CONSTANT')\n",
    "\n",
    "    tm = tf.contrib.image.translations_to_projective_transforms(tf.reshape(t, [-1, 2]))\n",
    "    rtm = tf.contrib.image.compose_transforms(rm, tm)\n",
    "    \n",
    "    # crash with GPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        ret = tf.contrib.image.transform(imgs, rtm, interpolation=\"BILINEAR\")\n",
    "\n",
    "    return ret\n",
    "\n",
    "def __affine_shape(shapes,r,t,isinv=False):\n",
    "    if isinv:\n",
    "        r = tf.matrix_inverse(r)\n",
    "        t = tf.matmul(-t,r)\n",
    "    shapes = tf.matmul(shapes,r) + t\n",
    "    return shapes\n",
    "def __gen_heatmap(shapes, IMAGE_SIZE=224):\n",
    "    __pixels__ = tf.constant([(x, y) for y in range(IMAGE_SIZE) for x in range(IMAGE_SIZE)],\n",
    "                                      dtype=tf.float32,shape=[1,IMAGE_SIZE,IMAGE_SIZE,2])\n",
    "    shapes = shapes[:,:,tf.newaxis,tf.newaxis,:]\n",
    "#     __pixels__ (1, 224, 224, 2)\n",
    "#     shapes (?, 68, 1, 1, 2)\n",
    "    value = __pixels__ - shapes\n",
    "#   value (?, 68, 224, 224, 2)\n",
    "    value = tf.norm(value,axis=-1)\n",
    "#   value2 (?, 68, 224, 224)\n",
    "    value = 1.0 / (tf.reduce_min(value,axis=1) + 1.0)\n",
    "#   value3 (?, 224, 224)\n",
    "    value = tf.expand_dims(value,axis=-1)\n",
    "#   value_o (?, 224, 224, 1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conn_layers(imgs, mean_s, s_current, fc_current):   \n",
    "    # Transformation estimation\n",
    "    r,t = __calc_affine_params(s_current, mean_s)\n",
    "    \n",
    "    # image transformation\n",
    "    T_img = __affine_image(imgs, r, t)\n",
    "    \n",
    "    # landmark transformation\n",
    "    T_pts=__affine_shape(s_current, r, t, isinv=False)\n",
    "    \n",
    "    # heatmap generation\n",
    "    hmap = __gen_heatmap(T_pts, IMAGE_SIZE//2)\n",
    "    \n",
    "    # feature generation\n",
    "    fm_flat = tf.layers.dense(fc_current,(IMAGE_SIZE // 4) ** 2,activation=tf.nn.relu)\n",
    "#     print('fm_flat', fm_flat)\n",
    "    fm = tf.reshape(fm_flat, shape = [-1,(IMAGE_SIZE // 4),(IMAGE_SIZE // 4), 1])\n",
    "    fmap = tf.image.resize_images(fm, (IMAGE_SIZE//2, IMAGE_SIZE//2), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    return T_img, hmap, fmap, T_pts, r, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAN_blk(imgs, s_mean, s_current, fc_current, train_phase, keeprate, name = 'DAN_blk'):\n",
    "    with tf.variable_scope(name):\n",
    "        T_img, hmap, fmap, T_pts, r, t = conn_layers(imgs, s_mean, s_current, fc_current)\n",
    "#         print('T_img', T_img)\n",
    "#         print('hmap', hmap)\n",
    "#         print('fmap', fmap)\n",
    "        igt_input = tf.concat([T_img, hmap, fmap], axis=3)\n",
    "    \n",
    "        delta_s, fc_next = FF_NN(igt_input, train_phase, keeprate)\n",
    "\n",
    "        s_next = T_pts + delta_s\n",
    "\n",
    "        s_next_inverse = __affine_shape(s_next, r, t, isinv=True)\n",
    "\n",
    "        return s_next_inverse, fc_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define Model Input (imgs, mean_s) and Output (pts_),  pts_ ~ f(imgs, mean_s)\n",
    "imgs = tf.placeholder(tf.float32, [None, 224,224,3])\n",
    "s_mean = tf.placeholder(tf.float32, [None,68,2]) # 136\n",
    "pts_ = tf.placeholder(tf.float32, [None,68,2]) # 136\n",
    "# control \n",
    "train_phase = tf.placeholder(tf.bool, name='phase_train')\n",
    "keeprate = tf.placeholder(tf.float32, name=\"keeprate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DAN model\n",
    "pts_flatten = tf.layers.flatten(pts_)\n",
    "mean_s_flatten = tf.layers.flatten(tf.cast(s_mean,dtype=tf.float32))\n",
    "\n",
    "imgs_in = tf.image.resize_images(imgs, (IMAGE_SIZE//2, IMAGE_SIZE//2), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "delta_s, fc1 = FF_NN(imgs_in, train_phase, keeprate)\n",
    "s1_out = tf.cast(s_mean,dtype=tf.float32) + delta_s\n",
    "\n",
    "# DAN block\n",
    "ds2, fc2 = DAN_blk(imgs_in, s_mean, s1_out, fc1, train_phase, keeprate, name = 'DAN_blk1')\n",
    "ds3, fc3 = DAN_blk(imgs_in, s_mean, ds2, fc2, train_phase, keeprate, name = 'DAN_blk2')\n",
    "ds4, fc4 = DAN_blk(imgs_in, s_mean, ds3, fc3, train_phase, keeprate, name = 'DAN_blk3')\n",
    "s2_out, _ = DAN_blk(imgs_in, s_mean, ds4, fc4, train_phase, keeprate, name = 'DAN_blk4')\n",
    "# print(s_out)\n",
    "# s_out_flatten = tf.layers.flatten(s_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_parameters 58965736\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "\n",
    "    total_parameters += variable_parameters\n",
    "print('total_parameters', total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Saver...\n"
     ]
    }
   ],
   "source": [
    "# Define the Model Loss (4)\n",
    "\n",
    "s1_losses = tf.reduce_mean(tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.squared_difference(pts_, s1_out),-1)),-1))\n",
    "s2_losses = tf.reduce_mean(tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.squared_difference(pts_, s2_out),-1)),-1))\n",
    "\n",
    "\n",
    "# Define the Optimizer (5)\n",
    "s1_train_step = tf.train.AdamOptimizer(0.001).minimize(s1_losses)\n",
    "s2_train_step = tf.train.AdamOptimizer(0.001).minimize(s2_losses)\n",
    "\n",
    "# initialize the model\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "print(\"Setting up Saver...\")\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session start ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "if (training == False):\n",
    "    ckpt = tf.train.get_checkpoint_state(logs_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('Loading sucessfully')\n",
    "    else:\n",
    "        print('No checkpoint file found')\n",
    "        raise\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data iterator\n",
    "def get_batch(X, Y, batch_size = 32):\n",
    "    # print ('shuffle training dataset')\n",
    "    idx = np.arange(len(X))    \n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        tb = int(len(X)/batch_size)\n",
    "        #print('total batches %d' % tb)\n",
    "        for b_idx in range(tb):\n",
    "            tar_idx = idx[(b_idx*batch_size):((b_idx+1)*batch_size)]\n",
    "            t_batch_x = X[tar_idx]\n",
    "            t_batch_y = Y[tar_idx]\n",
    "            # print(b_idx, t_batch_x.shape, t_batch_y.shape)\n",
    "            yield t_batch_x, t_batch_y\n",
    "\n",
    "def data_augmentation(images, pts, rot=(-30, 30), s=(0.6, 1.0)):\n",
    "    keypoints_on_images = []\n",
    "    for idx_img in range(images.shape[0]):\n",
    "        image = images[idx_img]\n",
    "        height, width = image.shape[0:2]\n",
    "        keypoints = []\n",
    "        for p in range(pts.shape[1]):\n",
    "            keypoints.append(ia.Keypoint(x=pts[idx_img,p,0], y=pts[idx_img,p,1]))\n",
    "        keypoints_on_images.append(ia.KeypointsOnImage(keypoints, shape=image.shape))\n",
    "\n",
    "    seq = iaa.Sequential([iaa.Affine(rotate=rot,scale=s)])\n",
    "    seq_det = seq.to_deterministic() # call this for each batch again, NOT only once at the start\n",
    "\n",
    "    # augment keypoints and images\n",
    "    images_aug = seq_det.augment_images(images)\n",
    "    keypoints_aug = seq_det.augment_keypoints(keypoints_on_images)\n",
    "    \n",
    "    pts_aug=[]\n",
    "    for img_idx, keypoints_after in enumerate(keypoints_aug):\n",
    "        img_pts_aug=[]\n",
    "        for kp_idx, keypoint in enumerate(keypoints_after.keypoints):\n",
    "            img_pts_aug.append([round(keypoint.x),round(keypoint.y)])\n",
    "        pts_aug.append(np.asarray(img_pts_aug))\n",
    "\n",
    "    pts_aug = np.asarray(pts_aug).astype(np.int32)\n",
    "    \n",
    "#     print('images_aug', images_aug.shape)\n",
    "#     print('pts_aug', pts_aug.shape)\n",
    "    return images_aug, pts_aug\n",
    "      \n",
    "# write image to file\n",
    "def write_result(batch_xs_valid, batch_pts, iter_num):\n",
    "    b = random.randint(0, batch_pts.shape[0]-1)\n",
    "    img = batch_xs_valid[b].copy()\n",
    "    pts = batch_pts[b] #print(pts)\n",
    "    for p in range(pts.shape[0]):\n",
    "        #print(\"p\",p, pts[p+1,0],pts[p+1,1])\n",
    "        cv2.circle(img,(pts[p,0],pts[p,1]), 2, (255,0,0), -1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imwrite('./dan/imgs/infer_'+str(iter_num)+'.png', img)\n",
    "    \n",
    "def eval_norm_error_image(infer, gt):\n",
    "    # loss of all landmarks\n",
    "    l2d = np.sum(np.sqrt(np.sum(np.square(infer-gt),axis=2)), axis=1)\n",
    "    # distance of eye corners\n",
    "    cd = np.sqrt(np.sum(np.square(gt[:,45,:]-gt[:,36,:]),axis=1))\n",
    "    norm_error_image = l2d/cd/68\n",
    "    return norm_error_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T] Step: 0, loss:206.895\n",
      "[V*] Step: 0, loss:207.059\n",
      "[T] Step: 500, loss:3.91331\n",
      "[V*] Step: 500, loss:4.45444\n",
      "[T] Step: 1000, loss:3.76438\n",
      "[V*] Step: 1000, loss:4.245\n",
      "[T] Step: 1500, loss:4.14252\n",
      "[V] Step: 1500, loss:4.54797\n",
      "[T] Step: 2000, loss:3.62823\n",
      "[V*] Step: 2000, loss:4.12358\n",
      "[T] Step: 2500, loss:3.71995\n",
      "[V] Step: 2500, loss:4.17129\n",
      "[T] Step: 3000, loss:3.75447\n",
      "[V] Step: 3000, loss:4.35928\n",
      "[T] Step: 3500, loss:3.73383\n",
      "[V] Step: 3500, loss:4.22593\n",
      "[T] Step: 4000, loss:3.61738\n",
      "[V] Step: 4000, loss:4.17972\n",
      "[T] Step: 4500, loss:3.57443\n",
      "[V*] Step: 4500, loss:4.1135\n",
      "[T] Step: 5000, loss:3.5207\n",
      "[V] Step: 5000, loss:4.12888\n",
      "[T] Step: 5500, loss:3.60988\n",
      "[V] Step: 5500, loss:4.25603\n",
      "[T] Step: 6000, loss:3.46964\n",
      "[V*] Step: 6000, loss:4.09751\n",
      "[T] Step: 6500, loss:3.59425\n",
      "[V] Step: 6500, loss:4.16251\n",
      "[T] Step: 7000, loss:3.51819\n",
      "[V*] Step: 7000, loss:4.02841\n",
      "[T] Step: 7500, loss:3.57499\n",
      "[V] Step: 7500, loss:4.21789\n",
      "[T] Step: 8000, loss:3.35026\n",
      "[V*] Step: 8000, loss:4.02535\n",
      "[T] Step: 8500, loss:3.37327\n",
      "[V] Step: 8500, loss:4.05621\n",
      "[T] Step: 9000, loss:3.50699\n",
      "[V] Step: 9000, loss:4.10429\n",
      "[T] Step: 9500, loss:3.33153\n",
      "[V*] Step: 9500, loss:3.98397\n",
      "[T] Step: 10000, loss:3.77891\n",
      "[V] Step: 10000, loss:4.38452\n",
      "[T] Step: 10500, loss:3.36817\n",
      "[V*] Step: 10500, loss:3.93594\n",
      "[T] Step: 11000, loss:3.33459\n",
      "[V] Step: 11000, loss:3.9972\n",
      "[T] Step: 11500, loss:3.84626\n",
      "[V] Step: 11500, loss:4.49024\n",
      "[T] Step: 12000, loss:4.12725\n",
      "[V] Step: 12000, loss:4.56165\n",
      "[T] Step: 12500, loss:3.20806\n",
      "[V*] Step: 12500, loss:3.93196\n",
      "[T] Step: 13000, loss:3.22996\n",
      "[V] Step: 13000, loss:4.0265\n",
      "[T] Step: 13500, loss:3.32032\n",
      "[V] Step: 13500, loss:4.016\n",
      "[T] Step: 14000, loss:3.07617\n",
      "[V*] Step: 14000, loss:3.86116\n",
      "[T] Step: 14500, loss:3.08363\n",
      "[V] Step: 14500, loss:3.91653\n",
      "[T] Step: 15000, loss:3.2961\n",
      "[V] Step: 15000, loss:4.07144\n",
      "[T] Step: 15500, loss:3.54459\n",
      "[V] Step: 15500, loss:4.23874\n",
      "[T] Step: 16000, loss:3.0137\n",
      "[V*] Step: 16000, loss:3.79569\n",
      "[T] Step: 16500, loss:2.97131\n",
      "[V] Step: 16500, loss:3.79779\n",
      "[T] Step: 17000, loss:3.08795\n",
      "[V] Step: 17000, loss:3.91015\n",
      "[T] Step: 17500, loss:2.98331\n",
      "[V*] Step: 17500, loss:3.78571\n",
      "[T] Step: 18000, loss:3.03531\n",
      "[V] Step: 18000, loss:3.79895\n",
      "[T] Step: 18500, loss:2.95316\n",
      "[V] Step: 18500, loss:3.86387\n",
      "[T] Step: 19000, loss:2.99746\n",
      "[V] Step: 19000, loss:3.90167\n",
      "[T] Step: 19500, loss:3.04957\n",
      "[V] Step: 19500, loss:3.9371\n",
      "[T] Step: 20000, loss:2.97405\n",
      "[V] Step: 20000, loss:3.91765\n",
      "[T] Step: 20500, loss:2.9521\n",
      "[V] Step: 20500, loss:3.83058\n",
      "[T] Step: 21000, loss:2.84278\n",
      "[V] Step: 21000, loss:3.87665\n",
      "[T] Step: 21500, loss:2.86605\n",
      "[V] Step: 21500, loss:3.91835\n",
      "[T] Step: 22000, loss:2.76401\n",
      "[V] Step: 22000, loss:3.79813\n",
      "[T] Step: 22500, loss:2.78503\n",
      "[V] Step: 22500, loss:3.84172\n",
      "[T] Step: 23000, loss:2.75358\n",
      "[V] Step: 23000, loss:3.83372\n",
      "[T] Step: 23500, loss:2.85543\n",
      "[V] Step: 23500, loss:3.93435\n",
      "[T] Step: 24000, loss:2.78394\n",
      "[V] Step: 24000, loss:3.89819\n",
      "[T] Step: 24500, loss:2.73032\n",
      "[V*] Step: 24500, loss:3.78216\n",
      "[T] Step: 25000, loss:2.70601\n",
      "[V] Step: 25000, loss:3.83551\n",
      "[T] Step: 25500, loss:3.02128\n",
      "[V] Step: 25500, loss:4.06458\n"
     ]
    }
   ],
   "source": [
    "avg_shape = np.expand_dims(np.round(np.mean(db_helen['pts']['trainset'], axis=0)),axis =0);#print(avg_shape.shape)\n",
    "if training == True:\n",
    "    batches = get_batch(db_helen['img']['trainset'], db_helen['pts']['trainset'], batch_size = batch_size)\n",
    "    valid_batches = get_batch(db_helen['img']['testset'], db_helen['pts']['testset'], batch_size = batch_size)\n",
    "    # pretrain FF_NN net\n",
    "#     for step in range(10000):\n",
    "#         batch_xs, batch_ys = next(batches)\n",
    "#         batch_xs_aug, batch_ys_aug =data_augmentation(batch_xs, batch_ys)\n",
    "#         sess.run([extra_update_ops,s1_train_step], feed_dict={imgs: batch_xs_aug,\n",
    "#                                                            pts_: batch_ys_aug,\n",
    "#                                                            s_mean:avg_shape,\n",
    "#                                                            train_phase: True,\n",
    "#                                                            keeprate:0.5})\n",
    "#         if (step % 1000 == 0):\n",
    "#             print(\"[PreT] Step: %d\" % (step))\n",
    "    \n",
    "    # Train Model for 1000 steps\n",
    "    hist_train_acc = []\n",
    "    hist_valid_acc = []\n",
    "    max_validloss = 99999\n",
    "    for step in range(MAX_ITERATION):\n",
    "        batch_xs, batch_ys = next(batches)\n",
    "        batch_xs_aug, batch_ys_aug =data_augmentation(batch_xs, batch_ys)\n",
    "\n",
    "        sess.run([extra_update_ops,s2_train_step], feed_dict={imgs: batch_xs_aug,\n",
    "                                                           pts_: batch_ys_aug,\n",
    "                                                           s_mean:avg_shape,\n",
    "                                                           train_phase: True,\n",
    "                                                           keeprate:0.5})\n",
    "\n",
    "        if (step % 500 == 0):\n",
    "            # get training accr\n",
    "            idx = np.arange(len(db_helen['img']['trainset']))    \n",
    "            tb = int(len(idx)/batch_size)\n",
    "            acc_train= []\n",
    "            for b_idx in range(tb):\n",
    "                tar_idx = idx[(b_idx*batch_size):((b_idx+1)*batch_size)]\n",
    "                t_batch_x = db_helen['img']['trainset'][tar_idx]\n",
    "                t_batch_y = db_helen['pts']['trainset'][tar_idx]\n",
    "                acc_train.append(sess.run(s2_losses, feed_dict={imgs: t_batch_x,\n",
    "                                                                 pts_: t_batch_y,\n",
    "                                                                 s_mean:avg_shape,\n",
    "                                                                 train_phase: False,\n",
    "                                                                 keeprate:1.0}))\n",
    "            print(\"[T] Step: %d, loss:%g\" % (step, np.mean(acc_train)))\n",
    "            \n",
    "            # get validation accr\n",
    "            idx = np.arange(len(db_helen['img']['testset']))  \n",
    "            tb = int(len(idx)/batch_size)\n",
    "#             t_batch_x = db_helen['img']['testset']#[tar_idx]\n",
    "#             t_batch_y = db_helen['pts']['testset']#[tar_idx]\n",
    "            acc_valid=[]\n",
    "            pts_valid=[]\n",
    "            for b_idx in range(tb):\n",
    "                tar_idx = idx[(b_idx*batch_size):((b_idx+1)*batch_size)]\n",
    "                t_batch_x = db_helen['img']['testset'][tar_idx]\n",
    "                t_batch_y = db_helen['pts']['testset'][tar_idx]\n",
    "\n",
    "                infered_pts, acc_loss= sess.run([s2_out, s2_losses],\n",
    "                                                 feed_dict={imgs: t_batch_x,\n",
    "                                                            pts_: t_batch_y,\n",
    "                                                            s_mean:avg_shape,\n",
    "                                                            train_phase: False,\n",
    "                                                            keeprate:1.0})\n",
    "                acc_valid.append(acc_loss)\n",
    "                pts_valid.append(infered_pts)\n",
    "                \n",
    "            infered_pts = np.reshape(np.asarray(pts_valid), newshape = [-1,68,2])\n",
    "    #             acc_valid.append(valid_loss)\n",
    "            write_result(db_helen['img']['testset'][np.arange(infered_pts.shape[0])], infered_pts, step)\n",
    "\n",
    "            if np.mean(acc_valid) < max_validloss:\n",
    "                saver.save(sess, logs_dir + \"model.ckpt\", step)\n",
    "                print(\"[V*] Step: %d, loss:%g\" % (step, np.mean(acc_valid)))\n",
    "                max_validloss = np.mean(acc_valid)\n",
    "            else:\n",
    "                print(\"[V] Step: %d, loss:%g\" % (step, np.mean(acc_valid)))\n",
    "\n",
    "            hist_train_acc.append(np.mean(acc_train))\n",
    "            hist_valid_acc.append(np.mean(acc_valid))\n",
    "# else: # evaluate\n",
    "#     batch_xs_valid, batch_ys_valid = next(valid_batches)\n",
    "#     t_batch_x = db_helen['img']['testset']#[tar_idx]\n",
    "#     t_batch_y = db_helen['pts']['testset']#[tar_idx]\n",
    "#     infered_pts, acc_valid= sess.run([tf.reshape(y,shape=(-1,68,2)), avg_losses], feed_dict={imgs: t_batch_x,\n",
    "#                                                                                              pts_: t_batch_y,\n",
    "#                                                                                              s_mean:avg_shape,\n",
    "#                                                                                              train_phase: False,\n",
    "#                                                                                              keeprate:1.0})\n",
    "#     norm_error_image = eval_norm_error_image(infered_pts, t_batch_y)\n",
    "#     pandas.DataFrame({'loss':norm_error_image}).to_csv('./dan/norm_error_image.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = 3\n",
    "img = db_helen['img']['testset'][3]\n",
    "pts = t_batch_y = db_helen['pts']['testset'][3]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "cv2.circle(img,(pts[36,0],pts[36,1]), 2, (255,0,0), -1)\n",
    "cv2.circle(img,(pts[45,0],pts[45,1]), 2, (255,0,0), -1)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
